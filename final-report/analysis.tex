\section{Interprocedural Analysis}\label{analysis}

We implemented our analysis as a fixed-point iteration
over the set of program statements. Our analysis performs
on the interprocedural control flow graph (ICFG) of the program.
Intraprocedural flow edges are gathered from each function
control flow graph, while interprocedural flow edges are
gathered from the program call graph built by LLVM. 

Our analysis dataflow set is $VarTaint \times Inst$,
where $VarTaint \subset Var$ is the set of tainted program
variables and $Inst$ the set of program statements. 
$Var$ represents the set of all program variables.
At a program point $p_n$, a dataflow set is composed
of a set of pairs $(v, S_v)$, where $v$ is a tainted
variable, and $S_v$ the set of statements where $v$
has been used before the $p_n$.
 
\subsection{Analysis algorithm} 

\begin{table}
\begin{tabular}{|l|l|}
\hline
\textbf{Symbols}	&	\textbf{Description}							\\ \hline
$D$					&	$VarTaint \times Inst$							\\
					&	Analysis dataflow set 							\\ \hline
$Inst$				&	Set of instructions in the program 				\\ \hline
$input$				&	$Inst\ \rightarrow\ D$ 							\\
					&	Function that returns the dataflow values		\\
		    		&	at the program point before an instruction 		\\ 	\hline
$output$			&	$Inst\ \rightarrow\ D$ 							\\
					&	Function that returns the dataflow values		\\
		    		&	at the program point after an instruction 		\\ 	\hline
$taintUse$			&	$VarTaint\ \rightarrow\ 2_{Inst}$ 				\\
					&	Function that returns program statements where	\\
		    		&	a tainted variable has been used	 			\\ 	\hline		    		
$worklist$			&	Set of remaining instructions to be processed 	\\ \hline
$Flow$				&	$Inst\ \rightarrow\ D$ 							\\
					&   Analysis flow function (Algorithm~\ref{fig:algoFlow}) 			\\ \hline
$first$				&	$Func \rightarrow\ Inst$ 						\\
					& 	Function that returns the first instruction		\\
					&	of a procedure									\\ \hline
$next$				&	$worklist\ \rightarrow\ Inst$ 					\\
					& 	Function that returns the next instructions		\\
					&	from the worklist								\\ \hline
$\pointsto{s}{q}$	&	Set of program locations to which variable q	\\
					&	may point to at the program statement $s$		\\
					& 	(i.e $q$'s \textit{points-to set} at statement $s$)	\\ \hline					
\end{tabular}
\caption{Algorithm Symbols}\label{symTable}
\end{table}

Algorithm~\ref{fig:algoAnalyze} represents the pseudo code of
our analysis algorithm\footnote{Adapted from Jonathan Aldrich's
lecture notes} \texttt{Analyze}, and Table~\ref{symTable}
describes the symbols we use.

\IncMargin{1em}
\begin{algorithm}
\caption{Analyze}\label{fig:algoAnalyze}
\SetAlgoLined
\LinesNumbered
\DontPrintSemicolon
\SetKwData{func}{f}
\SetKwData{varJ}{j}
\SetKwData{varI}{i}
\SetKwData{worklist}{worklist}
\SetKwFunction{Input}{inFlow}
\SetKwFunction{Output}{outFlow}
\SetKwFunction{Flow}{Flow}
\SetKwFunction{Update}{Update}
\SetKwFunction{InitDataFlow}{initDataFlow}
\SetKwFunction{Next}{next}
\SetKwFunction{Succs}{succs}
\SetKwFunction{AnalyzeAlgo}{Analyze}
\SetKwInOut{InData}{input}
\SetKwInOut{OutData}{output}


\InData{$\func: Proc, \newline
		 \InitDataFlow: Inst \rightarrow (VarTaint \times Inst)$}
%\OutData{$\&nbsp;$}
%\Input: VarTaint \rightarrow Inst, \newline
%\OutData{$\Output: VarTaint \rightarrow Inst$}
$ s_0 \leftarrow first(\func)$\;
$\Input[s_0] \leftarrow \InitDataFlow(s_0)$\;
$\worklist \leftarrow \set{s_0}$\;
\While{ $\worklist\ \neq\ \emptyset$ }{
	$\varI \leftarrow \Next(\worklist)$\;
	$\Output[i] \leftarrow \Flow(\AnalyzeAlgo, \varI, \Input[\varI])$\;
	\ForEach{ $\varJ \in \Succs(\varI)$ }{
		\If{ $\Output[\varI] \not\sqsubseteq \Input[\varJ]$}{
			$\Input[\varJ] \leftarrow \Input[\varJ] \sqcup \Output[\varI]$\;
			$\worklist \leftarrow \worklist \cup\ \set{\varJ}$\;
		}	
	}
}
\end{algorithm}
\DecMargin{1em}

%Before \texttt{Analyze} performs, an initial dataflow
%set of the program points is obtained through an
%intraprocedural dataflow analysis of program functions.
We define a set of C standard library functions that
we considered as sources. These library functions are not
further analyzed during \texttt{Analyze}'s run.
Instead we provide for them annotations that specify
which of their parameters becomes tainted after they
have run. Appendix !!! lists the C standard library
functions the analysis considers as sources.

On the other hand, we also predefine a set of functions
we consider as sinks. These functions are handled similarly
to the previous described sources. Appendix !!! lists
the C standard library functions the analysis considers
as sinks.

\texttt{Analyze} starts by storing the initial dataflow
set before the first program instruction $s_0$ and then
adds $s_0$ to the statement work list (\texttt{worklist}).
Then the program loops between line $4$ and $12$ until
the statement work list becomes empty.

For each loop, a statement $i$ is removed from
\texttt{worklist} and passed to the \texttt{Flow} function
with the dataflow set at the program point before $i$ (\texttt{input[i]}).
The function \texttt{Flow} returns the dataflow set for
the program point after statement $i$ (\texttt{output[i]}).

For each successor statement $j$ of $i$, if the new
dataflow set at $j$'s entry $j$ (\texttt{output}$[i]$)
is not smaller than the previous calculated set
(\texttt{output}$[i]\ \not\sqsubseteq\ $ \texttt{input}$[j]$),
\texttt{input}$[j]$ is updated and $j$ added to \texttt{worklist}.
On the other hand, if $j$ is not added to the work list, then
a fixed point has been reached at the program point before $j$.

This process is repeated until the statement work list
becomes empty, which means the analysis reached a
fixed point since no dataflow set changes again.

\IncMargin{1em}
\begin{algorithm}
\caption{Flow}\label{fig:algoFlow}
\SetAlgoLined
\LinesNumbered
\DontPrintSemicolon
\SetKwData{Input}{inFlow}
\SetKwData{Output}{outFlow}
\SetKwData{Caller}{caller}
\SetKwData{stmt}{inst}
\SetKwData{stmtV}{v}
\SetKwFunction{Map}{map}
\SetKwFunction{LCOPY}{COPY}
\SetKwFunction{LLOAD}{LOAD}
\SetKwFunction{LSTORE}{STORE}
\SetKwFunction{LADDROF}{ADDROF}
\SetKwFunction{LCALL}{CALL}
\SetKwFunction{LSOURCE}{SOURCE}
\SetKwFunction{LSINK}{SINK}
\SetKwFunction{Type}{Type}
\SetKwFunction{TaintUse}{taintUse}
\SetKwFunction{Update}{Update}
%\SetKwFunction{AnalyzeCallee}{AnalyzeCallee}
\SetKwFunction{Taint}{taint}
%\SetKwFunction{FindCompress}{FindCompress}
\SetKwInOut{InData}{input}
\SetKwInOut{OutData}{output}


\InData{$\Caller: Proc, \newline
		 \stmt: Inst, \newline
		 \Input: VarTaint \rightarrow Inst$}
\OutData{$\Output: VarTaint \rightarrow Inst$}
$\Output \leftarrow \Input$\;
\Switch{$\Type(\stmt)$}{
	\Case{$\LCOPY\ [p = q] $}{
		$\Output \leftarrow \Input \cup \set{(p, \set{\stmt})}$\;
	}
	\Case{$\LLOAD\ [p = *q] $}{
		\ForEach{$\stmtV \in \pointsto{\stmt}{q}$}{
			$S_{v} \leftarrow \TaintUse[\stmtV]$\;		
			$\Output \leftarrow \Input \cup \set{(\stmtV, S_v \cup \stmt)}$\;
		}
	}
%	\Case{$\mathbb{ADDROF}\ [p = \&a]$}{
%	}
	\Case{$\LSTORE\ [*p = q] $}{
		\ForEach{$\stmtV \in \pointsto{\stmt}{p}$}{
			$S_{v} \leftarrow \TaintUse[\stmtV]$\;
			$\Output \leftarrow \Input \cup \{ (\stmtV, S_{v} \cup \stmt) \}$\;
		}
	}	
	\uCase{$\LSINK\ [func(a_0, a_1, ..., a_n)]$}{
	}
	\Case{$\LSOURCE\ [func(a_0, a_1, ..., a_n)]$}{
		\ForEach{$i \in \set{0,1,...,n}$}{
			\If{$i \in \Taint(func)$}{			
				$S_{a_i} \leftarrow \TaintUse[a_i]$\;
				$\Output \leftarrow \Input \cup \set{ (a_i, S_{a_i} \cup \stmt) }$\;
			}			
		}
	}	
	\Case{$\LCALL\ [call\ func]$}{
		\If{$\Caller \neq func$}{
			$\Output \leftarrow \Flow(\Caller, func, \Input)$
		}
	}		
}
\end{algorithm}
\DecMargin{1em}

Function \texttt{Flow} (Algorithm~\ref{fig:algoFlow})
implements the analysis' transfer equations.

\subsection{Recursive and Mutual Recursive Function Calls} 

Our analysis ignore recursive functions calls: the dataflow set
before and after recursive calls are identical. 

We detect recursive mutual function calls by finding strongly
connected components of the ahead-of-time call graph generated
by LLVM. 

\subsection{Context-Sensitivity} 

We achieve context-sensitivity by analyzing callees
with dataflow set information of their formal parameters
at calling sites.

For instance in Figure~\ref{fig:sample}, the call to \even{} at
line $4$ would take into the account the fact that \texttt{x}
is tainted.
On the other hand, \even{}'s call at line $25$ can not safely
make this assumption.

\subsection{Motivating Example Case Study}\label{sec:sampleSummary}

\subsection{Handling of complex data structures}
